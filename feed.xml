<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://agostontorok.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://agostontorok.github.io/" rel="alternate" type="text/html" /><updated>2025-02-09T00:20:19+00:00</updated><id>http://agostontorok.github.io/feed.xml</id><title type="html">ágoston.török</title><subtitle>Agoston Torok&apos;s website</subtitle><author><name>Agoston Torok</name></author><entry><title type="html">Can you do data science without statistics knowledge?</title><link href="http://agostontorok.github.io/2021/04/15/data_sci_statistics/" rel="alternate" type="text/html" title="Can you do data science without statistics knowledge?" /><published>2021-04-15T00:00:00+00:00</published><updated>2021-04-15T00:00:00+00:00</updated><id>http://agostontorok.github.io/2021/04/15/data_sci_statistics</id><content type="html" xml:base="http://agostontorok.github.io/2021/04/15/data_sci_statistics/"><![CDATA[<p>Can you do data science without statistics knowledge?
With automation in machine learning the field opens up and one may ask whether we need stats skills in the future</p>

<h1 id="the-world-of-automated-machine-learning">The world of automated machine learning</h1>

<p>Today, if you want to be a data scientist there are countless courses promising quick entrance to the field of data. For sure, nobody believes that one can learn in a matter of weeks the ins and outs of a complex field that requires hard skills in math/stats, software engineering, and soft skills in R&amp;D development. Yet, because of automation it seems sensible to train machine learning technicians: people with knowledge of the tools and APIs that unleash the power of data analytics.
because of automation it seems sensible to train machine learning technicians
In fact, I’m also trying to use such tools as much as possible. The reason is that implementing any of these methods yourself is usually pointless and prone to bugs.</p>

<p>Read further on <a href="https://medium.datadriveninvestor.com/is-there-data-science-without-statistics-70d671649dc3">Medium</a></p>]]></content><author><name>Agoston Torok</name></author><category term="science" /><summary type="html"><![CDATA[Can you do data science without statistics knowledge? With automation in machine learning the field opens up and one may ask whether we need stats skills in the future]]></summary></entry><entry><title type="html">I published the first cartoons of The Data Department series</title><link href="http://agostontorok.github.io/2020/11/07/the_data_department/" rel="alternate" type="text/html" title="I published the first cartoons of The Data Department series" /><published>2020-11-07T00:00:00+00:00</published><updated>2020-11-07T00:00:00+00:00</updated><id>http://agostontorok.github.io/2020/11/07/the_data_department</id><content type="html" xml:base="http://agostontorok.github.io/2020/11/07/the_data_department/"><![CDATA[<p>I was working on the illustrations for my book when things got out of control :) I found myself drawing into the nights and I just could not stop. It’s kind of relaxing, kind of fun and I’m sure there are people like me who enjoys stats jokes. So here it is.</p>

<blockquote class="instagram-media" data-instgrm-captioned="" data-instgrm-permalink="https://www.instagram.com/p/CKJXCvWFoeY/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="13" style=" background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:540px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);"><div style="padding:16px;"> <a href="https://www.instagram.com/p/CKJXCvWFoeY/?utm_source=ig_embed&amp;utm_campaign=loading" style=" background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;" target="_blank"> <div style=" display: flex; flex-direction: row; align-items: center;"> <div style="background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;"></div> <div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center;"> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;"></div> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;"></div></div></div><div style="padding: 19% 0;"></div> <div style="display:block; height:50px; margin:0 auto 12px; width:50px;"><svg width="50px" height="50px" viewBox="0 0 60 60" version="1.1" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g transform="translate(-511.000000, -20.000000)" fill="#000000"><g><path d="M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631"></path></g></g></g></svg></div><div style="padding-top: 8px;"> <div style=" color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;"> View this post on Instagram</div></div><div style="padding: 12.5% 0;"></div> <div style="display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;"><div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);"></div> <div style="background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;"></div> <div style="background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);"></div></div><div style="margin-left: 8px;"> <div style=" background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;"></div> <div style=" width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)"></div></div><div style="margin-left: auto;"> <div style=" width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);"></div> <div style=" background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);"></div> <div style=" width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);"></div></div></div> <div style="display: flex; flex-direction: column; flex-grow: 1; justify-content: center; margin-bottom: 24px;"> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;"></div> <div style=" background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;"></div></div></a><p style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;"><a href="https://www.instagram.com/p/CKJXCvWFoeY/?utm_source=ig_embed&amp;utm_campaign=loading" style=" color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none;" target="_blank">A post shared by The Data Department - comics (@tddcomics)</a></p></div></blockquote>
<script async="" src="//www.instagram.com/embed.js"></script>]]></content><author><name>Agoston Torok</name></author><category term="comics" /><summary type="html"><![CDATA[I was working on the illustrations for my book when things got out of control :) I found myself drawing into the nights and I just could not stop. It’s kind of relaxing, kind of fun and I’m sure there are people like me who enjoys stats jokes. So here it is.]]></summary></entry><entry><title type="html">Why do overdue tasks take still a long time to finish?</title><link href="http://agostontorok.github.io/2020/04/01/time_estimates/" rel="alternate" type="text/html" title="Why do overdue tasks take still a long time to finish?" /><published>2020-04-01T00:00:00+00:00</published><updated>2020-04-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2020/04/01/time_estimates</id><content type="html" xml:base="http://agostontorok.github.io/2020/04/01/time_estimates/"><![CDATA[<p>The prototypical situation that has been puzzling me for a while is the following:<br />
_- We estimated 3 days for a task</p>
<ul>
  <li>Bob has been working on the task for 3 days already</li>
  <li>On the daily scrum, he says that he just needs to take care of a couple more things and the task will be finished</li>
  <li>The task is not finished the next day_</li>
</ul>

<p>Sometimes such tasks are not finished even after 5 days of work. Since they are typically “more research-less development” tasks, many people suggest accepting this kind of uncertainty as inherent to research. While I agree to a point, I don’t want to give up predictability so easily. A year ago, Erik Bernhardsson shared a <a href="https://erikbern.com/2019/04/15/why-software-projects-take-longer-than-you-think-a-statistical-model.html">fascinating blog post on time estimations</a>, concluding that the reason why development tasks take longer than expected is that the blowup factor (actual time/expected time) follows a lognormal distribution and our estimates are accurate for the Median but not so much for the Mean task completion time. I really liked his post and re-read it several times last year because it finally helped me to understand why is it so difficult to play scrum poker. I’m taking his model as the basis for my work here, to see if we need to finetune our estimate for task completion.</p>

<h4 id="estimates-are-smaller-than-expected-finishing-times">Estimates are smaller than expected finishing times</h4>

<p>When in the above example, Bob was 3 days into the task, it was intuitive to believe that he was really about to finish it. After all, the estimated time need for the task was 3 days. However, statistically speaking, our estimate of 3 days was an estimate for the Median of the underlying distribution. The Median of the distribution does not say too much about the scale of the values, it just says plain and simple that 50% of the time the task would be completed faster, and 50% of the time it would take longer than 3 days. A problem with the Median is that it is <strong>not</strong> sensitive to the uncertainty in the task. However, when you want to calculate the development time of a feature, you do want to take into account the uncertainty. Therefore, it is better to calculate the expected value for the task completion time for which we have pretty much all the information we need. Let’s see what this expected value would look like.</p>

<p>The expected value for the lognormal distribution is:</p>

\[\operatorname{E} = \exp(\mu + \frac{\sigma^2}{2})\]

<p>To calculate this, we need to know two parameters μ and σ. Luckily, we have an unbiased estimate for the Median, and since that is:</p>

\[Median = \exp(\mu)\]

<p>We have μ already. For σ, the case is a bit more tricky but not hopeless. Erik’s idea was to use the gut feeling of risk. My proposal, in addition, is to use the spread of the scrum poker estimates as an uncalibrated estimate for σ. To be sure, this is an uncalibrated estimate because — although it should be correlated with some sort of uncertainty — it still doesn’t reflect any particular scaling factor. Probably, this is also team and environment-dependent, so it’s best to estimate it based on the actual data collected from the sprints. Basically, you need the individual estimates and the actual time to be able to fit a simple model and get σ for your team. One addition: likely, the uncertainty around a task can be better estimated with a model that also factors in who the assignee is (no offence meant to anyone ;). Some people are better at streamlining, while others are much more conscious of details.</p>

<h4 id="the-bermuda-triangle-of-the-doing-column">The Bermuda triangle of the “Doing” column</h4>

<p>So let’s get back to the daily scrum where Bob said that he was about to finish the task that we estimated to take 3 days of work (just as a remark, Bob is a fictive person). The question is whether we should just accept that the mean completion time is bigger than our estimate (Median) anyway, or if there is more to this story than meets the eye.</p>

<p>Let’s say when we did the scrum poker we voted as follows: Me: 2; John: 2, Bob: 3, Sarah: 3, Linda: 5, Mary: 5. Based on this we had an estimate of 3 days. Now the three days passed, so the question is whether we should still stick to the same estimate? Actually, it turned out that both John and I were wrong in gauging the difficulty of the task, so one can already see intuitively that the Median of the remaining votes (discounting our lousy votes) can be considered to be higher (it is now 4 days!). More generally speaking, when we made our estimate before the task was started we took into account all kinds of outcomes, amongst them the case when the task could have been completed in a few minutes (perhaps if Bob had realized that the same feature already existed someplace but with a different name), to the absurd case of a very difficult implementation process (perhaps if the feature had been more complicated than we imagined). Statistically, we calculate the expected value by integrating over the entire distribution. Now for any time point <em>t</em> &gt; 0 it is evident that we can’t consider times between 0 and <em>t</em> in the integration and have to instead calculate the expected value as follows:</p>

\[\operatorname{E}[X] = \int_{t}^{\infty} x f(x)\, dx.\]

<p>Where <em>f(x)</em> is the conditional probability of <em>x</em> given that we consider points from <em>t</em> to <em>∞</em>. So we are not considering the cases which we already know did not materialize and are considering only cases when the task will take at least a time of <em>t</em> to be completed.</p>

<p>So although beyond the peak of the distribution, points right after <em>t</em> have a relatively higher probability than points farther away, there are much more points farther away and the curvature is also changing as it moves away from the peak, so the expected value is actually blowing up. Let’s demonstrate this through an example. Let’s take three cases to illustrate, (1) where the task is in “todo” phase and we have not started it yet, (2) where the task has already been worked on for the initially estimated time (blowup factor of 1), and (3) where the task has been worked on for double the initially estimated time (blowup factor of 2).</p>

<p><img src="https://cdn-images-1.medium.com/max/1000/1*R2GEZ5OapLO0L-tZlECiMg.png" alt="png" /></p>

<p>Now you see a paradoxical thing: the remaining time, operationalized by E_t — t, is not shrinking as we proceed but it is growing. This, of course, does not mean that we cannot finish tasks; it just helps to make increasingly better estimates for the remaining work by factoring the elapsed time into the equation. We can use this knowledge in multiple scenarios. First, it can help teams make better decisions on when to cut or restructure tasks, and in general to understand when they’re like to be finished (i.e. as a rule of thumb reject the notion of finishing in the next hour when the blowup factor is already 2).</p>

<p>Second, this knowledge is also critical to recognize tasks that are becoming impossible to finish in time. We have seen several tasks, which seemed tractable at first sight and then became the bogeyman of the project. It is essential to detect these as early as possible and rethink deliverables, handle expectations, and/or come up with alternative solutions.</p>

<p>Also, the assumption in this exercise is that during the execution of a task, there are no “feedback effects of inspection”. In reality, the feedback of the team during the daily scrum or of the stakeholders during a review may change the approach (with the distribution) and hence the expected time to finish too. In fact, if you look at the distribution of blowup factors in the <a href="https://github.com/Derek-Jones/SiP_dataset">SiP dataset</a> (which Erik also looked at) the right tail is not as heavy as one would expect from a standard lognormal distribution, my hypothesis is that it is exactly those feedback, control and restructuring mechanisms — which kick into action when the blowup factor becomes large — that are responsible for this. So, my main suggestion would be for teams to pay close attention to what plays out in the daily scrums to help avoid story completion time blowup.</p>

<p>Code is available on <a href="https://github.com/agostontorok/TaskCompletionTimeEstimation">github</a></p>

<p>Remarks:</p>

<ul>
  <li>Derek M. Jones has written  <a href="https://arxiv.org/pdf/1901.01621.pdf">an interesting paper</a>  based on his analysis of the SiP dataset. He is looking forward to analyzing your data as well for free with the condition that he can make an anonymized form of data publicly available. This is a great opportunity to get these parameters for your company.</li>
  <li>In the current post, I used the lognormal distribution, finding the best fitting distribution though is an active  <a href="http://shape-of-code.coding-guidelines.com/2012/09/03/descriptive-statistics-of-some-agile-feature-characteristics/">field of research</a>.</li>
  <li>In the SiP dataset estimates were made by single developers and not as a joint effort, also most of the estimates there are in the sub 2 days range.</li>
</ul>

<p>Thanks for the comments of  <a href="https://scholar.google.com/citations?user=5WMeN5UAAAAJ&amp;hl=en">Adam Csapo</a>,  <a href="https://dblp.uni-trier.de/pers/hd/h/Hahn:J=uuml=rgen_T=">Jürgen Hahn</a>  and  <a href="http://www.knosof.co.uk/ESEUR/">Derek M. Jones</a>  on the first draft.</p>]]></content><author><name>Agoston Torok</name></author><category term="productivity" /><category term="leadership" /><summary type="html"><![CDATA[The prototypical situation that has been puzzling me for a while is the following: _- We estimated 3 days for a task Bob has been working on the task for 3 days already On the daily scrum, he says that he just needs to take care of a couple more things and the task will be finished The task is not finished the next day_]]></summary></entry><entry><title type="html">Three challenges of the AI product lifecycle</title><link href="http://agostontorok.github.io/2020/02/01/challenges/" rel="alternate" type="text/html" title="Three challenges of the AI product lifecycle" /><published>2020-02-01T00:00:00+00:00</published><updated>2020-02-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2020/02/01/challenges</id><content type="html" xml:base="http://agostontorok.github.io/2020/02/01/challenges/"><![CDATA[<p>Working on AI products — Whether it is retail, IoT, or marketing — data scientists face similar challenges. Some of these challenges are general to many technology areas, others are specific to AI, due to its unique way this field blurs the boundaries between state-of-the-art research and application development. Let’s look at three prototypical examples of these challenges in the areas of business specification, iterative development of analytics, and testing.</p>

<h1 id="specification-of-business-requirements">Specification of business requirements</h1>

<h2 id="the-challenge">The challenge</h2>

<p>One of the most frequent topics that we data science practitioners like to talk about is the question of how business requirements are formulated. This can bring with it a variety of challenges depending on the perspective someone takes. On one end of the spectrum, we often like to make the claim that t_he people in charge of the business (the CEO, board, marketing team, sales team, product managers etc.) do not know what they want_. This is a frustrating place to be. On the other end of the spectrum, we often boast (without a hint of self-pity) that  <em>the business unit commissioned us to build something akin to a time machine or teleportation tube</em>. As you can imagine, this isn’t an enviable place to be in, either.</p>

<p><img class="  wp-image-74 alignright" src="https://miro.medium.com/max/1154/1*jL8sMUOela9ldwJb_wVu7w.jpeg" alt="" width="auto" height="350" />
<em>Meme created by the author using https://imgflip.com/</em></p>

<h2 id="the-solution">The solution</h2>

<p>Although these two issues seem remarkably different on the surface, their root cause is actually the same. To put it in simple terms, each development project has a value and a cost. Business people typically know the value of things. However, in the field of AI, the cost is much more difficult to figure out in advance. It’s so difficult that it is challenging even for us, just think about how often you struggle to come up with what number to show in the scrum poker for a story. There are just too many unknowns in the development phase, especially when we aim for the bleeding edge. Still, we data scientists are the people with the most information and therefore the widest perspective on the cost of development so we have an obligation to share what we know. Sure, the business leadership might push back, so we may be forced to settle for a less complex solution.  <strong>However, without this two-way communication link between the business and R&amp;D, the business either will either stall (see issue 1) or will rush into a decision and choose to stake its fortune in something clearly valuable (but perhaps unattainable, see issue 2).</strong>  So we, as data scientist, should not just wait for specifications to come. It is imperative that we forget waterfall-like requirement documents and begin such two-way conversations that will yield a product that is both feasible and valuable.</p>

<p>A related point is the notion of ‘just in time decisions’. Decisions are usually costly steps in development; when you decide to go for a neural network over a simple linear regression you make an important restriction on the possible solutions. Restrictions can turn out to be both positive and negative with time. Therefore,  it is crucial to postpone the introduction of restrictions until we have enough information  to predict their effect well. Usually, this is just before the moment when it gets “too late”. This, of course, results in an inherent feeling of uncertainty during the development process but knowing the underlying reasons should help to embrace it.</p>

<h1 id="iterative-development-of-analytics">Iterative development of analytics</h1>

<h2 id="the-challenge-1">The challenge</h2>

<p>Once the business decides to go for the development, another set of issues pops up. Iterative development as such is usually far from the researcher’s mind, resulting in conversations such as  <em>I either implement that deep convolutional network to classify the images or the problem will not be solved</em>  or  <em>Why would I bother implementing a baseline solution what it would perform like?</em>  In academic practice, it is often hard to argue with these points. The main focus is on novelty and not on invested time. While this motivation is the force pushing science beyond its boundaries every day, novelty in itself is not valuable. And the desperate search for novum in science can even be counterproductive (see the  <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a>).</p>

<h2 id="the-solution-1">The solution</h2>

<p>In data science, the main focus is on creating value.  <strong>Novelty is not a value per se, and even more importantly, value is not only the result of your work.</strong> To better highlight this, let me give an example. In data science, we often face situations when we know that there would be some really good solution to a challenge… if only we had a little more labelled data. In at least one specific case, my team was exactly in this situation. We were telling sales/marketing that we can give the predictions they want if they give us more data. They were telling that when we give them more precise predictions only then they can get more data. Vicious cycle. For an underfunded project this could easily be the death sentence, the data scientists are complaining because of the lack of data, the sales is complaining because of lack of results. Complaining still consumes resources (cost) but no value is created so the project will be cancelled. In our case, luckily, we quickly came to see that value is best understood as an insight we could  <em>deliver today</em>, no insight that we could  <em>hypothetically gain</em>  given more data. So we solved part of the problem with a much simpler model and gave sales better (but far from the best possible) predictions. That, in turn, enabled them to bring us more data. So in the next iteration, we were able to go for the more complex model.</p>

<p>Time — whether it be time spent running a program, doing research or carrying out a development project — is of the essence in commercial data science. Maybe you are working on a well-funded project so running out of money does not affect you on the short term. Still, even if you are working on some fresh topic, probably tens or even hundreds of other companies around the world are working on the same topic. You don’t have to be first all the time but it is vital to keep up with the pace and be there at every checkpoint. This is because  product development is not a sprint but a marathon, so your development style has to be like the body of a marathon runner as well. Marathon is not about sudden big leaps in various directions; it is about maintaining a predictable, steady pace over a long time.</p>

<p><img class="  wp-image-74 alignright" src="https://miro.medium.com/max/1000/1*qFaFHvw5s8kxGKoqczx56g.jpeg" alt="" width="auto" height="350" />
<em>Meme created by the author using https://imgflip.com/</em></p>

<h1 id="testing-and-validation">Testing and validation</h1>

<h2 id="the-challenge-2">The challenge</h2>

<p>You have a clear business need, you have a nice development flow, what can go wrong? You are trying to innovate in a structured way. Striving for predictability in cost and value could easily inhibit motivation for approaches which are less predictable. So it is crucial that we get feedback from our customers as often as possible so that we can learn what is of most value to them. That way we can steer development to more costly but also substantially more valuable directions. This feedback is operationalized in the form of testing. Testing for an AI-powered product is essential.  <strong>Developing a full-fledged AI product takes a lot of time and money, so developing something that doesn’t directly address business needs is a huge waste.</strong></p>

<h2 id="the-solution-2">The solution</h2>

<p>Data science problems are often so complex that you have to abstract away from the real challenge to solve them. Here, I use the word  <em>abstract</em> in the sense that we use data from the past that is (maybe somehow) filtered, (maybe somehow) labelled; we use that instead of future data that may come in an unselected, unfiltered, and unlabelled form. While this may sound trivial it’s also something that you have to keep in mind constantly. Forgetting this leads to discussions such as  <em>“but it showed a really good fit on my test set”.</em> Not once have I heard of a model going into production based on its performance in the abstract (training-validation-test set) case, without monitoring whether its performance generalizes to the concrete situation as well.</p>

<p>In many cases, data scientists opt for the ritual of looking at metrics on test sets and cross-validation scores and forget that generalization is much more important than those numbers. In fact, the numbers that you see (e.g. F1 score) is not the actual accuracy of your model. The F1 score that you see is only an estimate of the true, population-wide F1 score. Interestingly though, it is difficult to tell how far the sampled F1 score is from the population F1 score. Data scientists must rely on their experience and even their gut feeling for this. It is somewhat ironic that in a field where we are so obsessed with numbers there is still so much space for expert intuition.</p>

<p>It is bad practice, though, to not try to quantify these kinds of intuitions. Let me explain what I mean. When I see an F1 score of 0.98 I should start to worry because that number is simply too high for most real-world scenarios. It could be that I made a mistake and my test samples were present in the training set, or that there was a feature that, when available, exactly predicted the output class. Let’s say I checked both of these potential causes and noticed that the latter was the case so I calm down and submit the code.</p>

<p>What’s wrong here? I had a good intuition, investigated it, and made sure that the model is correct. True… but apart from this anecdote, there is no documentation of this exploration. This means that the next time someone else trains a new iteration model she has to go through the same discovery again (see relearning as a source of waste in the lean literature). So the ideal outcome of the investigation is that I split the test set into two parts: in one I have the definitive feature, in the other, I have examples without that feature. I maybe even set different F1 measure acceptance criteria for them. This way, I’m communicating my expert intuition for subsequent data scientists working on the product.</p>

<p>Thanks to  <a href="https://medium.com/@divenyijanos">Janos Divenyi</a> and to  <a href="https://scholar.google.com/citations?user=5WMeN5UAAAAJ&amp;hl=en">Adam Csapo</a>  for their useful comments on the first version of this post.</p>]]></content><author><name>Agoston Torok</name></author><category term="leadership" /><category term="business" /><category term="product management" /><summary type="html"><![CDATA[Working on AI products — Whether it is retail, IoT, or marketing — data scientists face similar challenges. Some of these challenges are general to many technology areas, others are specific to AI, due to its unique way this field blurs the boundaries between state-of-the-art research and application development. Let’s look at three prototypical examples of these challenges in the areas of business specification, iterative development of analytics, and testing.]]></summary></entry><entry><title type="html">Lean + Data Science</title><link href="http://agostontorok.github.io/2019/08/01/lean/" rel="alternate" type="text/html" title="Lean + Data Science" /><published>2019-08-01T00:00:00+00:00</published><updated>2019-08-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2019/08/01/lean</id><content type="html" xml:base="http://agostontorok.github.io/2019/08/01/lean/"><![CDATA[<p>I joined this field because of the excitement that we feel upon discovering new patterns in data. With time though, it became clear that identifying patterns is just the first half of this journey. There is another part, which is about sharing this discovery. ‘Sharing’ can be in the form of a presentation, in the form of a change in an existing product or even an entirely new product. Thus the two parts together — nurturing ideas from inception to a product — is the full stack of data science.</p>

<p>In this post, I’m sharing my experience on how to build machine learning models into the software in efficient ways. Before going into details, let’s put up some underlying assumptions:</p>

<ul>
  <li>Product development requires money. Some companies have more some have less, but, they all want to see a return on their investment.</li>
  <li>Product development requires time. Time is a universally short supply; therefore, we should make sure to have some ROI anytime we suddenly run out of it.</li>
  <li>Product development is inherently uncertain. I don’t know what will be the final feature set of the product that we just started to develop, and probably not even the client knows. In this case, we can do two things: 1) be honest and find out together 2) pretend that we know what the market wants (and more often than not fail miserably).</li>
</ul>

<h1 id="lean-product-development-in-data-science">Lean product development in data science</h1>

<p>Lean manufacturing has a proven track record in several industries. Although it was originally formed as a methodology for the automobile industry, it has been extended to software development as well, thanks to the  <a href="https://www.amazon.com/Lean-Software-Development-Agile-Toolkit/dp/0321150783">brilliant work of Mary and Tom Poppendieck</a>. The central tenet of lean is to reduce waste in the process to maximise productivity. The Poppendiecks identify seven types of waste for software. Here they are, anchored to data science practices.</p>

<ol>
  <li><strong>Partially done work</strong>. I consider most Jupyter notebooks as prime examples. They are partially done work because you usually do not add either documentation or tests. Importantly, it’s not a waste in the past: it’s waste in the future. Waste every time someone wonders what that purpose of that notebook was? Waste every time someone wants to build from it and it turns out that you left off with a not linear run of the cells.</li>
  <li><strong>Extra features</strong>. Not so long ago we were really pushing the roll-out of a feature because we wanted to prove that it works. It worked. Unfortunately, we did not see that the question was not doubt in whether the feature would work from a machine learning perspective but doubt whether it would work on the market. Because of this misunderstanding, we wasted two weeks of effort and a few hours on maintenance from time to time.</li>
  <li><strong>Relearning</strong>. A straightforward illustration is that code that everyone writes from scratch every time but is intricate enough to spend a good 2 hours reimplementing it. Think of reading the data, setting up the cross-validation etc.</li>
  <li><strong>Handoffs</strong>. A little bit different from relearning in the sense that this is something you can’t avoid. Code handover, though, can be optimised as a process. One prominent place of handover that I often see is between prototyping and product data teams.</li>
  <li><strong>Task switching</strong>. You are in a hurry — which is the usual case — so you decide to work on two features at the same time. Maybe you even do this because otherwise, you feel that you would spend too much time on one and won’t have time for the second.</li>
  <li><strong>Delays</strong>. Approval time on a budget, on allocation, waiting for QA, waiting for a model to train, waiting for the tests to pass and so on. Although it would be ideal if in these times people could relax for 10 minutes, usually that does not happen. Instead because of frustration, they start working around it (e.g. begin implementing the next feature).</li>
  <li><strong>Defects</strong>. Loss goes NaN; the probability is 1.2; model serialised in a different version, missing data in production… And so on. Writing well-covered code does not mean you are not going to face defects, but fixing those defects will be significantly easier.</li>
</ol>

<p>We can easily agree that reducing these wastes certainly helps in providing more reliable output. The usual question is whether there is a way to overcome these wastes in a time and cost-efficient way. I believe that the key is embracing the uncertainty and design for that from day 1.</p>

<h1 id="embracing-uncertainty">Embracing uncertainty</h1>

<p>Embracing uncertainty means accepting the fact that we don’t know everything. We don’t know if that GAN is going to be better than some simple affine transformation for data generation, we don’t know if the product idea that we have now is of any interest to real customers, we don’t know many things. However, we can have good practices that help us answer these questions in the right way at the right time.</p>

<p><img class="  wp-image-74 alignright" src="https://miro.medium.com/max/1400/1*O6oviG37CJVeDa7y8HEh0w.png" alt="" width="auto" height="350" />
<em>Harry called everyone for a brainstorming meeting to do some market research. The aim of the meeting is to finetune the scope of the company’s next breakthrough product.</em></p>

<p>The bases of these good practices are communication and hypotheses. In a  <a href="https://medium.com/@torokagoston/test-driven-development-and-data-science-cf78ec3a9ed0">previous post</a>  of this series, I was already talking about the importance of hypotheses. That time it was hypotheses on the unit and system level, here, I’m going to talk about the importance of hypotheses on the business unit level. The  <a href="https://www.cbinsights.com/research/startup-failure-reasons-top/">most important reason for products failing</a>  is not meeting the market need. What often happens with data science products is that the team is delaying the release because, e.g. the model is not performing well in all cases. Then when the release finally happens suddenly, no one seems to care.</p>

<p>The reason behind these stories is a wrong concept of product development. Before implementing a feature for one year, we first have to make sure that the feature is needed.  Let’s t<a href="https://x.ai/blog/the-x-ai-story-chapter-1/">ake the story of x.ai</a> am AI-driven meeting scheduler. They had ideas about how to solve the problem with machine learning, but instead of implementing it from the ground up first, they started to test the concept with the help of a human meeting scheduler. They have learnt tremendously about the market needs and thanks to that now they have a growing business. This was only possible by making the right choice to embrace uncertainty and reduce waste by not implementing features before it was clear whether they are bringing value to the customers.</p>

<h1 id="the-full-stack-of-data-science">The full stack of data science</h1>

<p>A senior colleague of mine asked me after reading the TDD post how much that is for data scientists, how much for software engineers interacting with them and how much for data engineers. This question made me think of how I see the data science practice. I understand the data science team as a special part of the software development process. Since machine learning requires an in-depth knowledge of math (especially statistics), people often join from various non-software development fields to the team. That is good since these skills are traditionally missing from software engineering studies.</p>

<p><img class="  wp-image-74 alignright" src="https://miro.medium.com/max/1400/1*QTVtzD7iqhjYhkSZRyf_4w.png" alt="" width="auto" height="350" />
<em>Sometimes waste is hard to distinguish from the expertise.</em></p>

<p>However, a machine learning model is part of the software and therefore, it has to be seamlessly integrated. Let’s say you have built an excellent image classifier but it does not fit the target device memory; the data points on the stream are not arriving in temporal order; we have to read the data very fast in order to provide realtime feedback; the output of the model should be displayed in a valid yet easy to understand way. This means a good data scientist should have an understanding of the end to end process as well.</p>

<p>Nowadays the market calls such professional the full-stack data scientist (and we often refer as the unicorn). I can also add here that the way how someone becomes a full-stack data scientist is fastest via communication. You go to the desk of the software developer and ask (it’s okay to ask even two times the same thing). You learn from the DevOps colleague when he is explaining how he solves efficiently the model deployment. You tell your new idea of model access to the data engineer maybe she already implemented that feature or knows about it. Luckily, I have several examples with colleagues who became data science unicorns by this simple recipe.</p>

<p>As a final thought, I’m convinced that before looking for unicorns in the job market, all company should look inside and see whether they can nurture it. It could be that the answer is ‘yes, but we don’t have time for that’ nevertheless only the culture nurturing such talents can utilize their full potential.</p>]]></content><author><name>Agoston Torok</name></author><category term="product management" /><category term="productivity" /><category term="leadership" /><summary type="html"><![CDATA[I joined this field because of the excitement that we feel upon discovering new patterns in data. With time though, it became clear that identifying patterns is just the first half of this journey. There is another part, which is about sharing this discovery. ‘Sharing’ can be in the form of a presentation, in the form of a change in an existing product or even an entirely new product. Thus the two parts together — nurturing ideas from inception to a product — is the full stack of data science.]]></summary></entry><entry><title type="html">Test-driven development and data science</title><link href="http://agostontorok.github.io/2019/03/01/effectivedsteams3/" rel="alternate" type="text/html" title="Test-driven development and data science" /><published>2019-03-01T00:00:00+00:00</published><updated>2019-03-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2019/03/01/effectivedsteams3</id><content type="html" xml:base="http://agostontorok.github.io/2019/03/01/effectivedsteams3/"><![CDATA[<p>The previous two posts of this series were about the business and people perspectives of effective data science teams. However, in themselves they are only necessary but sufficient conditions: without the right tools and processes, the recipe does not work.</p>

<p>Therefore, in the next parts, I’m going to discuss some of the tools and processes that I consider important for a data science team. This part is about how to consolidate the practices of data analysis with the practices of software development. The specific part that I’m going to focus on is test-driven development (aka. TDD) for data analysis.</p>

<p>At first, I intended this also as a post around stories and conclusions, like the previous ones. But since I did not find any good tutorials online that would explain TDD from scratch to a working model, I’ve decided to make one myself to supplement this post. If you are familiar with TDD and would like jump right to the tutorial then <a href="https://nbviewer.jupyter.org/github/agostontorok/tdd_data_analysis/blob/master/TDD%20in%20data%20analysis%20-%20Step-by-step%20tutorial.ipynb">click here</a>. In the following, I introduce shortly TDD, the reasons why I think TDD is useful in data analysis, and then I conclude with a complete step-by-step TDD workflow using an example project from Kaggle.</p>

<h1 id="test-driven-development">Test-Driven Development</h1>
<p>Test-driven development is popularized by Kent Beck, the father of extreme programming. It helps development teams to focus on the required features and helps rapid iteration of versions. The main idea is that when you think of a new feature that you have to add to the code, first add a test that expects that feature to be present and see it FAIL. Then, write the quickest solution to PASS this test. Once it was passed take some time to REFACTOR the code. All three parts of the process are equally important and they work best in this order.</p>

<p>Take for example the first step: fail. I remember when some time ago, we were sitting in front of the computer with my colleagues and were looking at why changing the input parameters of a function does not change the output in an expected way although there was a unit test covering exactly that function. After some investigation, it turned out that the mentioned unit test, which I wrote <em>after</em> the function was created, could actually never fail.</p>

<p>The next important thing is to focus on only passing the actual test and not writing code that is intended to pass all possible tests in the future. One mantra helping in this is to ‘Keep it simple, stupid’ (KISS) that is often written on the wall of an IT office. Serious TDD practitioners literally stop as soon as the test passed and switch writing the next test if no refactoring needed. This yields short cycles of fail-pass iterations (aka. the flow). Also, the refactoring should not mean changing the test logic or completely rewriting the function that passed it. If you feel for example that the function is duplicated or has too many parameters then refactor.</p>

<p><img class="  wp-image-74 alignright" src="/public/img/edst3_1.jpeg" alt="" width="auto" height="350" />
<em>Test-driven development reduces the time for maintenance if you have time in between maintenance tasks to switch to test-driven development.</em></p>

<h1 id="tdd-for-analytics">TDD for analytics</h1>
<p>Now, one can say: alright this is nice and true for writing software for production but how does it relate to my practice when I do exploratory data science. First, I’m sure you met the situation when something that you calculated in your notebook in — let’s say — Jupyter is not working in the next stage of the development. Maybe the fields were not matching, maybe the datatypes, or maybe a seed was not fixed. Second, it should sound familiar when the data just drags you down into the rabbit hole: you notice that a linear model does not explain enough variance so you try some non-linear ones, then you see also that some missing values can be predicted so you predict those, then you see that maybe the data should be transformed, some string columns should be vectorized, others should be levels of an ordinal scale etc. Then, 2 weeks into the exploration the manager asks where is the result that you promised for one week ago and you can only explain to him what will be your next steps… And you still did not reduce the uncertainty for her. And she still does not know if the feature/model is needed at all or we should concentrate on other promising directions.</p>

<p>And third, there is <a href="http://science.sciencemag.org/content/280/5366/1014.full?view=full">craftsmanship</a> in data science as well. Although we read about the nice new discoveries in machine learning, the researchers that made those discoveries had to follow a rigorous stream of steps before they even had a chance to try out something new. They had to follow the principled way of data access, cleaning, transforming, modelling, and validation, which we all follow. Nevertheless, this is a very complex process with lots of things to pay attention to. TDD helps in keeping these steps modular. It facilitates replication, extension, and falsification. There are even <a href="https://github.com/Thenerdstation/mltest">libraries</a> that aim at providing some general tests to help out practitioners.</p>

<p>On top of these empirical considerations, there are theoretical ones as well. <a href="https://www.oreilly.com/library/view/thoughtful-machine-learning/9781449374075/ch01.html">TDD and scientific methodology are very similar</a>. When you create a test and see it failing is basically making a scientific hypothesis that is <a href="https://en.wikipedia.org/wiki/Falsifiability">falsifiable</a>. When you pass the test that is basically equivalent to the statistical testing of your experimental manipulation in a research study. Finally, refactoring is similar to the function of the discussion part of a paper: you turn your experimental manipulation to a theory.</p>

<p><img class="  wp-image-74 alignright" src="/public/img/edst3_2.jpeg" alt="" width="auto" height="350" />
<em>John has to remember that agility comes with a price.</em></p>

<h1 id="testing-sanity-and-insanity">Testing Sanity and Insanity</h1>
<p>Although software testing has its own jargon (unit, integration, system testing), I consider for some time another way of looking at tests that drive your development. I think about tests of insanity and sanity. Testing insanity means that you want to make sure that the feature that you created is not producing non-sensical results. For example, it gives some result for input A and some other result for input B, that is it is not insane. You also want to make sure that your model is trained, that it expects the right features and outputs in the expected range. However, no client is going to pay for a solution that is guaranteed to be not insane. This is only a necessary but not sufficient condition. For that our solution has to be sane. Therefore sanity testing assesses some higher level and even abstract hypotheses; e.g. that your solution (take a deep neural network) is better than a simple arithmetic average or that you are not overfitting the training data.</p>

<p>These are features that can be translated easily into direct business value. Financial software requires very strong arguments to choose a deep learning solution over an interpretable model when they can lose huge money instantly with a bad decision. Also, when you are already overfitting the training data when you compare it to the validation sets then imagine the how much difference you are going to see between the expected and the real fit for a dataset that was collected in a later batch. The way I think about these it: passing sanity tests sell your model passing insanity tests warrants customer satisfaction in the upcoming months and years of using your model.</p>

<p>Now let’s take a practical tone. As they say, it is often difficult to tell the fine line between a madman and a genius. The same goes for the question of ‘should I put this test in the insanity or in the sanity bucket?’. So, at this point, it is time to delve into the step-by-step tutorial. I took an example dataset from Kaggle, the <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">House Prices dataset</a> this is a sufficiently easy and fun data. Just right to pass the imaginary test of ‘tutorial on TDD for analysis’.</p>

<p><a href="https://nbviewer.jupyter.org/github/agostontorok/tdd_data_analysis/blob/master/TDD%20in%20data%20analysis%20-%20Step-by-step%20tutorial.ipynb">Aaand here is the notebook with the step by step guide</a></p>]]></content><author><name>Agoston Torok</name></author><category term="leadership" /><category term="business" /><category term="comics" /><summary type="html"><![CDATA[The previous two posts of this series were about the business and people perspectives of effective data science teams. However, in themselves they are only necessary but sufficient conditions: without the right tools and processes, the recipe does not work.]]></summary></entry><entry><title type="html">From talents to assets</title><link href="http://agostontorok.github.io/2019/02/01/effectivedsteams2/" rel="alternate" type="text/html" title="From talents to assets" /><published>2019-02-01T00:00:00+00:00</published><updated>2019-02-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2019/02/01/effectivedsteams2</id><content type="html" xml:base="http://agostontorok.github.io/2019/02/01/effectivedsteams2/"><![CDATA[<p>After the first part of this mini-series, I received some very interesting insights from fellow data professionals. Interestingly, one of the recurring topics was talent management. This topic is also very close to me. I know from first-hand experience that without good mentors and talent management I would never have been able to get to this point and still enjoy so much my everyday work. In this article, I would like to discuss the two specific aspects of talent management. The first is nurturing talent during internships and the second is whether a computer science dropout or a fresh PhD is better material for a data scientist.</p>

<p>One could argue that hiring is more about acquiring talents and not about talent management. In my opinion, though the term talent management is better suited to emphasize the interactive nature of the hiring and onboarding process. Here, one must keep in mind that highly intelligent people require room and guidance to develop and probably will never be able to work longer for a fat paycheck. To realize the importance of this claim just consider how much money it takes to get a good data scientist. Early employee turnover means essentially wasting financial assets. Therefore, the below lines are not only about an effective data science team from the R&amp;D point of view but also making it in a business aware and cost-effective way.</p>

<h1 id="interning-in-a-data-science-team">Interning in a data science team</h1>
<p>Today, if you study some STEM subject at the university, chances are you have already met the myriad of opportunities to enter the data science world. Banks, marketing companies, IT giants, and {food, health, etc.}-tech startups are looking for entry level data scientists to bolster their data team.</p>

<p>For many people, the prime requirement for an internship is that it should be at some well-known company. This is a valid consideration but here I would rather talk about some other points to take into account. Because in my opinion, doing an internship is not only about making your resume look better, rather about jumpstarting your career by learning about the practice of the field. I mean, there is nothing more disappointing when after looking at some impressive CV, on the interview the person shows mediocre performance… So let’s take one by one, the 3 points to consider when you choose your internship.</p>

<p>(1) The most important thing I feel often lacking from internships is focus: you get to the company and are going to work on basically everything that other people don’t want to or don’t have time to. This may even sound great first because you have the chance to try several methods, packages, data types etc. But be aware that this is something that you can also try on Kaggle, Drivendata or KDDCup. On the other hand, focused, ML-based product development is something that you can only learn by doing it at a company. This means you are going to learn about why and how to use machine learning methods to design something useful (on the price of trying fewer methods/packages/libraries).</p>

<p>(2) This brings us to the next point: accountability. I remember once catching a conversation at a conference banquet where a senior colleague was talking about how he usually gives interns some tasks but then forgets even what they are doing, not mentioning where they are at with what they are doing. This happens more often than you think.</p>

<p>If you are a senior just think about how excited you were when you first entered the work-life. Leverage this and get real work done by your interns. Even if they seem to be not senior enough for any of the tasks your team is facing, mind that they are eager to learn and challenge is the best motivation. If you are an intern, consider that one of the most valuable lessons you can experience during an internship is responsibility. Openness to taking responsibilities is a characteristic I am also looking for during interviews.</p>

<p><img class="  wp-image-74 alignright" src="/public/img/edst2_1.png" alt="" width="auto" height="350" />
<em>John is learning the hard way that interns today are not only looking for cool projects at a job fair but are often collecting fantastic swags as well. They have to bring next time some … as bait.</em></p>

<p>(3) The third point: find the intersection of hot and cold. Hot topics are easy to find in data science, just look at what was the most discussed topics last year at NeurIPS or ICML and chances are you find companies trying those ideas already today. Cold, on the other hand, is harder to find. Let me explain: it does not take 10+ years to see that there is a lot of hype on the field and often it turns out that this effective “new” method is actually a refurbished control theory application running on a big computer. Seeing this is extremely valuable since it enables to see also the connections, limitations and consequences based on several decades of research. This helps also to learn about the context where the new models born. So try to find a place where hot and cold meet. Hot in itself means just using trial-and-error model building and trust that the data behaves well (it never does..). Cold in itself means ignorance to any new addition to the field, and although the basis is often some classical theory but there are important additions in every major breakthrough that should not be ignored. So as Katy Perry sung: hot ’n’ cold.</p>

<p>Although, these points are recommendations for the position seeking intern but I’m also looking for the same qualities in the candidates during an interview. This leads us to the next point because besides these characteristics there are important experience factors that make certain data scientists more attractive to a company.</p>

<h1 id="phd-or-converted-software-engineer">PhD or converted software engineer?</h1>
<p>Everyone knows that the ideal data scientist has a PhD, knows Hadoop, Spark, and Docker, has 5+ year of business experience, 7 publications at top ML conferences and is under 25 years. Also, everyone knows that these <a href="https://en.wikipedia.org/wiki/Purple_squirrel">data science unicorns</a> rarely found in the real world. So the question is where to make compromises. One of such is whether a company should choose someone with deep statistical/ML background and experience in the ups and downs of working with real data (aka. PhD) or someone who has practical experience in how to efficiently write production level code and store data in a concise, safe and easy-to-access manner (aka. Converted software engineer hereafter referred as CSE).</p>

<p><img class="  wp-image-74 alignright" src="/public/img/edst2_2.png" alt="" width="auto" height="350" />
<em>Mind that an interview is challenging. Even for a data science unicorn.</em></p>

<p>I wish there was an answer to this. The problem is that these groups show variance as well. You can easily find a PhD who writes better code than a CSE and a CSE who knows clustering methods better than a PhD. On average PhD people from academia are inferior in coding and CSE people have more lacking mathematical foundations. But this difference should only bother you if you randomly (!) choose from the pool of CVs and hire the person who that CV belongs to. Then — of course — because of the nature of random variables you have a higher probability of ending up with someone writing better code if that person is incidentally a CSE.</p>

<p>But I am sure that I can safely say that no company is making costly hiring decisions by random selection. Instead, they want to know more about the candidate to reduce the uncertainty about his/her future performance. So let’s stop acting like it is a random selection because this whole thing brings lots of frustration to the people working in data science. Many of my friends coming from the software engineering track are frustrated because they don’t have the Dr. prefix while others with the PhD are doing totally unnecessary code polishing because they want to show their coding skills. And as the manager, the last thing you want in your team is frustration when you expect them to be creative.</p>

<p>I think avoiding this evil loop it is essential to have a mentor who helps mitigate the frustration and drives the person in the intricate path of becoming a real data scientist. Years ago, when I joined Synetiq that mentor was Adam Divak, the CTO of the company. Before founding the company, he was running brain simulations on supercomputers and had an outstanding interest in complex systems. Everyone knew him as the goto person with whatever technical problem and he is one of the few people I know who strives for perfectionism and can stop because of pragmatism. I was the guy from academia, coding in Matlab, not knowing git, unaware of all software engineering jargon (i.e. CRUD). But I really wanted to take this chance, so when I got one week to complete the interview task, I learned Python to the level to be able to submit the code. When I told on the interview that I learned it just for this task, I saw a genuine surprise in his eyes. From that time he looked closely my progress. During my trial period, every day after work I spent extra hours to study the tools I was supposed to work with and understand the methods that I was supposed to use. I quickly understood many new methods and utilized my existing knowledge in various tasks. Still, I was frustrated and did not feel that I’m improving enough. Now I know that this is a warning sign of an incoming burnout.</p>

<p>That is the point when a good mentor has to be there. I was lucky when Adam saw it. He asked me to update him on my progress at the end of each workday. This update often meant an extra hour of work for both of us but he took the effort and made sure that I can focus on the things that matter. He explained to me that knowing the meaning of all git commands does not make a good data scientist; understanding the data, the methods, and being able to make the right inferences do. So I should not feel less because I don’t speak all the CS talk, that will come with time. And he was right.</p>

<p>All of us — no matter PhD or CSE — have frustrations and lacks in knowledge but also strong sides and potentials. This is true for any team, anywhere in the world. A good mentor sees beyond the stereotypes and can help you with reaching full potential. Ideally, this starts as early as the interview process so try to find a manager that you feel could help to take your next step in the career path. Of course, reaching full potential is not necessarily an easy way but one worth taking definitely.</p>]]></content><author><name>Agoston Torok</name></author><category term="leadership" /><category term="business" /><category term="comics" /><summary type="html"><![CDATA[After the first part of this mini-series, I received some very interesting insights from fellow data professionals. Interestingly, one of the recurring topics was talent management. This topic is also very close to me. I know from first-hand experience that without good mentors and talent management I would never have been able to get to this point and still enjoy so much my everyday work. In this article, I would like to discuss the two specific aspects of talent management. The first is nurturing talent during internships and the second is whether a computer science dropout or a fresh PhD is better material for a data scientist.]]></summary></entry><entry><title type="html">Business vision in effective data science teams</title><link href="http://agostontorok.github.io/2019/01/01/effectivedsteams1/" rel="alternate" type="text/html" title="Business vision in effective data science teams" /><published>2019-01-01T00:00:00+00:00</published><updated>2019-01-01T00:00:00+00:00</updated><id>http://agostontorok.github.io/2019/01/01/effectivedsteams1</id><content type="html" xml:base="http://agostontorok.github.io/2019/01/01/effectivedsteams1/"><![CDATA[<p>This is the first part of a mini-series that summarizes my impressions on what makes certain data science teams effective. Over the years, I have worked in several teams: teams of various sizes, from as small as a duo to as large as a dozen data experts; and of various players, from college dropout savants through rebranded software engineers to PhD/postdocs with long years of academic experience. My role was also changing, I started as a junior and with time and experience developed to be a team lead.</p>

<p>Data science is a new field. It is so new that even the term data science is only <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2001.tb00477.x">12 years old</a>. It is a vibrant field though, a meeting point of people with different backgrounds, forming best practices, and high hopes from the stakeholders. The constellation of these factors makes it impossible to blindly generalize everything that we know about effective teamwork to the field of data science. Nevertheless, I think there is a recipe that turns the right ingredients — smart people — into that vital edge the company needs.</p>

<p>This recipe starts with the aspect I most often hear from managers: realizing the place of the data science team in the entire business. It’s tempting to believe that data science salaries are high because we are that smart but it could not be farther from the truth. The high salary is the effect of the high (anticipated) value that the company expects from the data science team. This means that the everyday job of a data scientist in a business environment should be not so much about inventing a new network architecture as about solving critical challenges in finite time.</p>

<h1 id="data-science-step-by-step">Data science step-by-step</h1>

<p><img class="  wp-image-74 alignright" src="/public/img/edst1_1.png" alt="" width="auto" height="350" />
<em>John is contemplating a two doors dilemma. One seems to be a really big area to explore but the other has a nice ergonomic chair…</em></p>

<p>Many people would think at this point that the latter takes away the essence of working on a cutting edge field. Actually, it’s the opposite, coming up with a new network architecture is frustrating: it requires not only a smart person but also years of experience on the field and a social network of fellow researchers to think together about the problem. Without these (and <a href="https://www.nature.com/articles/d41586-018-04023-5">even often together with these</a>), most of the individuals simply burn out during the quest, in a matter of years. And mind that a career lasts decades, not years.</p>

<p>Focusing on mission-critical challenges and time — on the other hand — helps in seeing the goal as something tangible. If your task is to optimize the layout of the company webpage for optimal conversion rate then you can see the effect of your work anytime. Tangible goals are also easier to chunk into subgoals that you can separately address. Let’s say that you want to build a robot that waves back when you wave at it, this requires a computer vision solution to recognize waving and a control solution that would function the response of the robot. Easier than completing the task of “build a social robot”, right? The waving robot is a less capable output I understand, but it’s an output that is actually produced and enables the next step in the social robot direction.</p>

<p>Actually, something very similar is going on in successful research labs as well. I remember first time meeting Elisa Ferre when I was working on a project at UCL, London. At that time, she was a postdoc at the lab of Patrick Haggard, one of the most productive labs at the whole university. She had a very clear focus on the aims of the experiment we were designing. This helped to remove every aspect that was not critical to the success of the experiment. She efficiently chunked the work to design, pilot, and experiment parts and defined S.M.A.R.T goals for each part. She did it not based on reading books on how to do project management but based on the first-hand experience with a dozen similar projects over the years. I was amazed. At that point understood that top universities are not necessarily about people being smarter but about smart people doing research very efficiently.</p>

<h1 id="the-role-of-an-expert">The role of an expert</h1>

<p><img class="  wp-image-74 alignright" src="/public/img/edst1_2.png" alt="" width="auto" height="350" />
<em>Mike has another meeting in 5 minutes and wants to know before that if it should be A or B…</em></p>

<p>In this field the more senior you are the more often you will be asked by the stakeholders for expert advice. Here is an example situation:</p>

<p><em>CEO: John, I understand you spent the last three weeks with investigating whether we should run our campaign with Gal Gadot or Margot Robbie. So: who should we choose?</em></p>

<p><em>DS: We investigated the problem using the following approach: we looked at the preferences of the followers of our Facebook, Twitter and Instagram pages. Then we compared the occurrence of Gal Gadot and Margot Robbie likes in these three groups using chi-square statistics, we found significant differences for Facebook and Twitter but not for Instagram. We did not merge these groups because we understand that the user-base of the three platforms is different and thought that this way you get a more fine-grained picture. Then, because overall the size of the intersection between our followers and that of Gal Gadot or Margot Robbie was small we tried to predict if a person would like Margot Robbie and/or Gal Gadot based on all of their known preferences using collaborative filtering. In that analysis, we decided to predict the preference for ten other actresses as well, which could also be the face of our campaign. These were Scarlett Johannson, … blablabla.</em></p>

<p>I bet for most of us this story just got interesting, so why did I not finish? Well, first of all, do you really think that John will finish this line of thought by saying <em>“my analysis shows, you should choose Gal Gadot/Margot Robbie”</em> or something like <em>“I think if we would build a recurrent neural network then we would understand how the interest of our followers changed over time for the different actresses…”</em>. Let’s clarify things a bit, the question of the CEO was <em>“what do you predict, would we sell more perfume with Gal Gadot or with Margot Robbie in the ad?”</em> What she expected was simply “Gal Gadot”. Most of the CEOs have no knowledge of the chi-square statistics, of the kernel trick, or the reparametrization, but they don’t need that, they have you for that. What they need is the ability to make the right business decisions once they have the necessary knowledge. But the necessary knowledge is again not understanding stochastic processes or linear algebra, only whether your analysis tells (A or B) and how certain you are about that. All the details are secondary.</p>

<p>I remember hearing from a fellow data scientist, that he wants to tell all the details to the manager because the manager has all the business information and he should have all the scientific information as well in order to make a decision. That sounds fair, except that as I said most managers don’t have the credentials to fully appreciate what does a p-value mean or what is the limitation the Gaussian assumption in the Kalman filter. For them, this is all information that just increases the uncertainty of the project for them, whereas a trained data expert should be able to differentiate between more and less important limitations. So next time you are asked for an expert advice try to give one and say “Based on the data, the better choice is Gal Gadot”.</p>

<h1 id="we-are-making-the-change">We are making the change</h1>

<p><img class="  wp-image-74 alignright" src="/public/img/edst1_3.png" alt="" width="auto" height="350" />
<em>Deadline day. John is expecting Marc to deliver his solution for the project. He did not understand why Marc was asking for more time to develop the solution.</em></p>

<p>So far I talked about more of the individual perspective, but before ending these thoughts it is necessary to talk about the team perspective as well. What is common in the communication of Google, Apple, Amazon and Netflix leaders and employees? Just listen to how Sundar Pichai, Tim Cook, Jeff Bezos or Reed Hastings talk about what they are doing. <em>We are introducing, we’ve found, and our vision</em> are just some of the expressions you can hear in these talks, not any I’m introducing, I’ve found or even my vision. These keynotes are texted carefully to bring a very important message through: we (aka. the people of the company) are making the change. This message is crucial because it lets people being part of the greater whole. Understanding the business goal as a manager is not enough, solely your understanding will not bring the best performance of your team. They also need to understand it, which is easiest if they can relate to it and see their role in enabling something grand.</p>

<p>In 1962, when JFK visited a NASA facility, he met a janitor and asked what he was doing, the janitor’s response was <em>“I’m helping put a man on the Moon”</em>. That is, he was not just cleaning the floor of some building, he was making sure that his colleagues — that happen to be astronauts — can do their job in the nicest, most hygienic environment possible that would stimulate their creativity and help them reach the Moon. That janitor had a really unique talent and not many people see their job this way. Oftentimes, despite actually putting people on the Moon. If you read this article, chances are that you and your colleagues are working on something that is close in significance to flying to the Moon. The problem with that is twofold. First, we are spending 8+ hours of our day at the workplace; it is much more satisfying to feel that our time is translated to an actual change in the state of the world. Second, perhaps even more important from the perspective of the current post, if you don’t see the relation of your work to any bigger picture then you are not able to bring the best out of yourself simply because you don’t know the place of your work and its relation to others’ works or to the final product. This is especially true for jobs requiring high abstraction capability and creativity.</p>

<p>The take-home message from this is that when you are a manager and see the place of the data science team in the business that’s good but you should not stop there. You should help to bring this knowledge in connection to the work of each individual in your team. This is not only telling them the motto of the company but rather translating it into data science terms and filling it up with content that they can relate their work to. At AGT, we work on the future of sport using IOT. This is the bigger picture, from a very high level. My job is to translate this to tangible goals for us and find which machine learning tools and how they can help to reach them. Having this system view, I believe, is essential for a data science team so that all these minds can understand the role of the features they enable and the consequences of having suboptimal performance, runtime, or generalization ability for their models.</p>

<p>Interesting questions, of course, come after having this covered. So stay tuned to learn about agile development work in a data science teams, expectation management, talent management and much more. If you have any questions or topics that you want to hear more about let me know in the comment section.</p>]]></content><author><name>Agoston Torok</name></author><category term="leadership" /><category term="business" /><category term="comics" /><summary type="html"><![CDATA[This is the first part of a mini-series that summarizes my impressions on what makes certain data science teams effective. Over the years, I have worked in several teams: teams of various sizes, from as small as a duo to as large as a dozen data experts; and of various players, from college dropout savants through rebranded software engineers to PhD/postdocs with long years of academic experience. My role was also changing, I started as a junior and with time and experience developed to be a team lead.]]></summary></entry><entry><title type="html">Our chapter is out in a Springer book</title><link href="http://agostontorok.github.io/2018/09/04/coginfocombook/" rel="alternate" type="text/html" title="Our chapter is out in a Springer book" /><published>2018-09-04T00:00:00+00:00</published><updated>2018-09-04T00:00:00+00:00</updated><id>http://agostontorok.github.io/2018/09/04/coginfocombook</id><content type="html" xml:base="http://agostontorok.github.io/2018/09/04/coginfocombook/"><![CDATA[<p>So this is a big day: our chapter on Cognitive Data Visualization has been published in the series Topics in Intelligent Engineering and Informatics. Aaand… this is the first time that my work can be found in <a href="https://books.google.co.uk/books?hl=en&amp;lr=&amp;id=a8hqDwAAQBAJ&amp;oi=fnd&amp;pg=PA49&amp;ots=Fg_RZz0mHt&amp;sig=Xs9DOaf4afTlkaYvc5LVzJ5ISaM#v=onepage&amp;q&amp;f=false">books.google.com</a> :)</p>

<p>The chapter is also - historically - the first work I co-authored with my dad. It was a very interesting experience to work together on this and this is reflected from the title to the end of the chapter. It’s also terrific to think about that it took 25 years of studying and knowledge gathering on my end to get to this point.</p>]]></content><author><name>Agoston Torok</name></author><category term="science" /><category term="virtual reality" /><category term="infographics" /><category term="storytelling" /><summary type="html"><![CDATA[So this is a big day: our chapter on Cognitive Data Visualization has been published in the series Topics in Intelligent Engineering and Informatics. Aaand… this is the first time that my work can be found in books.google.com :)]]></summary></entry><entry><title type="html">The price of data and GDPR</title><link href="http://agostontorok.github.io/2018/04/28/gdpr/" rel="alternate" type="text/html" title="The price of data and GDPR" /><published>2018-04-28T00:00:00+00:00</published><updated>2018-04-28T00:00:00+00:00</updated><id>http://agostontorok.github.io/2018/04/28/gdpr</id><content type="html" xml:base="http://agostontorok.github.io/2018/04/28/gdpr/"><![CDATA[<p>25 May 2018. The enforcement day of the famous or infamous GDPR, alias the EU General Data Protection Regulation. From that day, the current situation of data ownership and control changes… or does it.</p>

<p>I made this word cloud in the shape of the EU from the top 200 search results of a Google search on GDPR and these words made me think.</p>

<p><img class="  wp-image-74 alignright" src="/public/img/gdpr_wordcloud.png" alt="GDPR buzzwords" width="auto" height="auto" /></p>

<p>Like many on the field, I often quote the saying ‘data is the new oil’.  This means data is the thing that makes our civilization going forward. It is the fuel that runs the algorithms inside our phones, smart TVs, self-driving cars, everything. Take it away and the magic breaks, the algorithms struggle, the motion stops.</p>

<p>And as fossil fuel, data has to have its price as well. Currently everywhere, and after 25 May everywhere except Europe the data is cheap. I know, you read that data scientists are paid well, but rest assured, nobody in the world takes a salary that would change what I said: data is cheap.</p>

<p>Not only cheap, but what is even more important: unregulated. There are existing laws and regulations, yes, but <a href="https://www.youtube.com/watch?v=ofIlP1gJ-Ho">the internet is dark and full of terrors</a>: individuals, small companies, and large enterprises are escaping these regulations in various ways. I mean this situation is so twisted that even <a href="https://www.youtube.com/watch?v=mPjgRKW_Jmk&amp;t=404s">John Oliver covered it</a>.</p>

<p>The price of data will increase in Europe from 25 May 2018. People, the providers of this great source of renewable energy gets back some of the control over their data. The same data that makes these fantastic tools working, but the same data that is used often not in their best interest. I am thinking of things like the <a href="https://en.wikipedia.org/wiki/Cambridge_Analytica">Cambridge Analytica</a> scandal.</p>

<p>It is a little difficult to see how much power we have to shape the world by providing our data because it is decentralized. So how we can still guarantee that the data we provide is only used for the aims we provide it? I believe the first step is to change our behaviour. If there is a cookie pop up it is not a must to accept it; you can choose to browse without it but it is a little annoying to have that pop up everytime you visit the website. Still you can choose.</p>

<p>Facebook sent an update over their privacy and security policies some days ago. I bet data guys and girls in the Facebook data science team tracked the time spent on reading the updates. Now, they have this data on their computer and I imagine they are doing facepalm by seeing the distribution of reading times. <a href="https://en.wikipedia.org/wiki/HumancentiPad">Because people don’t read these complicated legal texts</a>.</p>

<p>Good news, intelligible and easily accessible consent forms are one of the <a href="https://www.eugdpr.org/key-changes.html">key changes of GPDR</a>. But it’s not only the EU, or Facebook, or Google or any big company which can help keeping us data providers safe. We are also responsible to sell our data to parties who we want to and only as long as we used their service. So for a start head to your <a href="https://www.facebook.com/settings?tab=applications&amp;section=inactive">Facebook applications settings</a> and remove Cambridge Analytica along with any parties who you don’t even remember when you gave access.</p>

<p>As the late Neil Armstrong said once: That’s one small step for man, one giant leap for mankind.</p>]]></content><author><name>Agoston Torok</name></author><category term="regulations" /><category term="social causes" /><summary type="html"><![CDATA[25 May 2018. The enforcement day of the famous or infamous GDPR, alias the EU General Data Protection Regulation. From that day, the current situation of data ownership and control changes… or does it.]]></summary></entry></feed>